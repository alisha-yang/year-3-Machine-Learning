{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "classes = ['Sydney', 'Melbourne', 'Brisbane', 'Perth']\n",
    "train_raw = pd.read_csv('train-raw.tsv', sep='\\t', names=['class', 'text']).reset_index(drop=True)\n",
    "X_train_raw = train_raw['text']\n",
    "y_train = train_raw['class']\n",
    "\n",
    "dev_raw = pd.read_csv('dev-raw.tsv', sep='\\t', names=['class', 'text']).reset_index()\n",
    "X_dev_raw = dev_raw['text']\n",
    "y_test = dev_raw['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectoriser = CountVectorizer()\n",
    "X_train = vectoriser.fit_transform(X_train_raw)\n",
    "X_test = vectoriser.transform(X_dev_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37300, 10) (103360, 10)\n"
     ]
    }
   ],
   "source": [
    "#testing to see if it's working well\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "x2 = SelectKBest(chi2, k=10)\n",
    "X_train_x2 = x2.fit_transform(X_train,y_train)\n",
    "X_test_x2 = x2.transform(X_test)\n",
    "\n",
    "print(X_test_x2.shape, X_train_x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brisbane\n",
      "melbourne\n",
      "perth\n",
      "sydney\n",
      "u0627\n",
      "u0644\n",
      "u0645\n",
      "u0646\n",
      "u0648\n",
      "u064a\n"
     ]
    }
   ],
   "source": [
    "#testing chi-square\n",
    "for feat_num in x2.get_support(indices=True):\n",
    "    print(vectoriser.get_feature_names()[feat_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 100 GNB features x2 acc 0.30107238605898123\n",
      "k 100 MNB features x2 acc 0.30053619302949064\n",
      "k 100 one-r features x2 acc 0.26246648793565686\n",
      "k 100 1-nearest neighbour features x2 acc 0.2975871313672922\n",
      "k 100 5-nearest neighbour features x2 acc 0.2988471849865952\n",
      "k 100 Decision Tree features x2 acc 0.30343163538873996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "models = [GaussianNB(),\n",
    "          MultinomialNB(),\n",
    "          DecisionTreeClassifier(max_depth=1),\n",
    "          KNeighborsClassifier(n_neighbors=1),\n",
    "          KNeighborsClassifier(n_neighbors=5),\n",
    "          DecisionTreeClassifier(max_depth=None)]\n",
    "#          svm.LinearSVC(C=C),\n",
    "#          svm.SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "#          svm.SVC(kernel='poly', degree=3, C=C)]\n",
    "titles = ['GNB',\n",
    "          'MNB',\n",
    "          'one-r',\n",
    "          '1-nearest neighbour',\n",
    "          '5-nearest neighbour',\n",
    "          'Decision Tree']\n",
    "#          'LinearSVC',\n",
    "#          'SVM with a cubic kernel',\n",
    "#          'SVM with an RBF kernel']\n",
    "\n",
    "k = 100\n",
    "\n",
    "x2 = SelectKBest(chi2, k=k)\n",
    "x2.fit(X_train,y_train)\n",
    "X_train_x2 = x2.transform(X_train)\n",
    "X_test_x2 = x2.transform(X_test)\n",
    "\n",
    "\n",
    "Xs = [(X_train_x2, X_test_x2)]\n",
    "X_names = ['x2']\n",
    "for title, model in zip(titles, models):\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t.todense(), y_train)\n",
    "        acc = model.score(X_test_t.todense(), y_test)\n",
    "        print('k', k, title, 'features', X_name, 'acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3087848297213622\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X_train_x2, y_train, cv=kfold)\n",
    "print(results.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
